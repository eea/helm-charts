apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ .Release.Name }}-data
  labels:
    {{- include "appl.labels" . | nindent 4 }}
    component: data

spec:
  replicas: {{ .Values.esworker.replicaCount }}
  serviceName: {{ .Release.Name }}-data

  selector:
    matchLabels:
      {{- include "appl.selectorLabels" . | nindent 6 }}
      component: data

  template:
    metadata:
      labels:
        {{- include "appl.selectorLabels" . | nindent 8 }}
        component: data

    spec:
      terminationGracePeriodSeconds: 300
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "appl.serviceAccountName" . }}
      
      {{- if .Values.esmaster.password }}
      initContainers:
      - name: config-init
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
        command: ['sh', '-c']
        args:
          - |
            echo "Initializing Elasticsearch configuration for data node..."
            # Copy config files from ConfigMap to shared volume
            cp /tmp/config/* /usr/share/elasticsearch/config/
            
            # Wait for certificates to be available (generated by master)
            if [ ! -f /usr/share/elasticsearch/config/elastic-certificates.p12 ]; then
              echo "Waiting for SSL certificates to be generated by master..."
              while [ ! -f /usr/share/elasticsearch/config/elastic-certificates.p12 ]; do
                echo "Certificates not yet available, waiting 5 seconds..."
                sleep 5
              done
              echo "SSL certificates found, continuing..."
            else
              echo "SSL certificates already exist"
            fi
            
            # Set proper permissions
            chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/config/
            echo "Configuration initialization completed"
        volumeMounts:
        - mountPath: /usr/share/elasticsearch/config
          name: elasticconfig
        - mountPath: /tmp/config
          name: elasticsearch-config
        securityContext:
          runAsUser: 0
      {{- end }}
      
      containers:
      - name: {{ .Release.Name }}-data
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
        env:
        - name: cluster.name
          value: "{{ .Values.clusterName }}"
        - name: node.name
          value: "${HOSTNAME}"
        - name: cluster.initial_master_nodes
          value: "{{- range $i := until (int .Values.esmaster.replicaCount) }}{{ $.Release.Name }}-master-{{ $i }}{{ if lt $i (sub (int $.Values.esmaster.replicaCount) 1) }},{{ end }}{{- end }}"
        - name: discovery.seed_hosts
          value: "{{- $masterList := list -}}{{- range $i := until (int .Values.esmaster.replicaCount) -}}{{- $masterList = append $masterList (printf "%s-master-%d.%s-master.%s.svc.cluster.local" $.Release.Name $i $.Release.Name $.Release.Namespace) -}}{{- end -}}{{- $workerList := list -}}{{- range $i := until (int .Values.esworker.replicaCount) -}}{{- $workerList = append $workerList (printf "%s-data-%d.%s-data.%s.svc.cluster.local" $.Release.Name $i $.Release.Name $.Release.Namespace) -}}{{- end -}}{{- $allNodes := concat $masterList $workerList -}}{{ join "," $allNodes }}"
        - name: bootstrap.memory_lock
          value: "{{ .Values.bootstrapMemoryLock }}"
        - name: node.roles
          value: "data"
        {{- if .Values.useMonitoring }}
        - name: xpack.monitoring.collection.enabled
          value: "true"
        {{- end }}
        {{- if .Values.esmaster.password }}
        - name: xpack.security.enabled
          value: "true"
        - name: xpack.security.transport.ssl.enabled
          value: "true"
        - name: xpack.security.transport.ssl.verification_mode
          value: "certificate"
        - name: xpack.security.transport.ssl.keystore.path
          value: "elastic-certificates.p12"
        - name: xpack.security.transport.ssl.truststore.path
          value: "elastic-certificates.p12"
        - name: elastic_password
          value: "{{ .Values.esmaster.password }}"
        - name: kibana_system_password
          value: "{{ .Values.kibana.password }}"
        - name: DO_NOT_CREATE_USERS
          value: "yes"
        {{- else }}
        - name: xpack.security.enabled
          value: "false"
        - name: xpack.security.transport.ssl.enabled
          value: "false"
        {{- end }}
        {{- if .Values.esmaster.backup.enabled }}
        - name: path.repo
          value: "/backup"
        {{- end }}
        - name: TZ
          value: "{{ .Values.timezone }}"
        - name: ES_JAVA_OPTS
          value: "-Xms{{ .Values.dataHeapSize }} -Xmx{{ .Values.dataHeapSize }}"
        - name: cluster.routing.allocation.disk.watermark.high
          value: "95%"
        - name: cluster.routing.allocation.disk.watermark.low
          value: "93%"

        ports:
        - containerPort: 9200
        - containerPort: 9300

        startupProbe:
          tcpSocket:
            port: 9200
          initialDelaySeconds: {{ .Values.esworker.healthChecks.startup.initialDelaySeconds }}
          periodSeconds: {{ .Values.esworker.healthChecks.startup.periodSeconds }}
          timeoutSeconds: {{ .Values.esworker.healthChecks.startup.timeoutSeconds }}
          failureThreshold: {{ .Values.esworker.healthChecks.startup.failureThreshold }}
          successThreshold: {{ .Values.esworker.healthChecks.startup.successThreshold }}

        livenessProbe:
          tcpSocket:
            port: 9200
          initialDelaySeconds: {{ .Values.esworker.healthChecks.liveness.initialDelaySeconds }}
          periodSeconds: {{ .Values.esworker.healthChecks.liveness.periodSeconds }}
          timeoutSeconds: {{ .Values.esworker.healthChecks.liveness.timeoutSeconds }}
          failureThreshold: {{ .Values.esworker.healthChecks.liveness.failureThreshold }}
          successThreshold: {{ .Values.esworker.healthChecks.liveness.successThreshold }}

        lifecycle:
          preStop:
            exec:
              command:
              - sh
              - -c
              - |
                echo "Starting graceful shutdown of data node..."
                # Disable shard allocation to prevent data movement during shutdown
                {{- if .Values.esmaster.password }}
                curl -s -X PUT -u "elastic:{{ .Values.esmaster.password }}" "http://localhost:9200/_cluster/settings" \
                  -H "Content-Type: application/json" \
                  -d '{"persistent": {"cluster.routing.allocation.enable": "primaries"}}' || true
                {{- else }}
                curl -s -X PUT "http://localhost:9200/_cluster/settings" \
                  -H "Content-Type: application/json" \
                  -d '{"persistent": {"cluster.routing.allocation.enable": "primaries"}}' || true
                {{- end }}
                
                # Wait for ongoing operations to complete
                echo "Waiting for ongoing operations to complete..."
                sleep 30
                
                # Flush and sync
                {{- if .Values.esmaster.password }}
                curl -s -X POST -u "elastic:{{ .Values.esmaster.password }}" "http://localhost:9200/_flush/synced" || true
                {{- else }}
                curl -s -X POST "http://localhost:9200/_flush/synced" || true
                {{- end }}
                
                echo "Graceful shutdown preparation completed"

        resources:
          requests:
            memory: {{ .Values.dataMemReservation }}
          limits:
            memory: {{ .Values.dataMemLimit }}
            # Equivalent to ulimits nofile 65536
            ephemeral-storage: 1Gi

        securityContext:
          {{- if .Values.bootstrapMemoryLock }}
          capabilities:
            add:
            - IPC_LOCK
          {{- end }}

        volumeMounts:
        - mountPath: /usr/share/elasticsearch/data
          name: esworkdata
        {{- if .Values.esmaster.backup.enabled }}
        - mountPath: /backup
          name: esbackup
        {{- end }}
        {{- if .Values.esmaster.password }}
        - mountPath: /usr/share/elasticsearch/config
          name: elasticconfig
        {{- end }}

      volumes:
      {{- if not .Values.esworker.persistence.enabled }}
      - name: esworkdata
        emptyDir:
          sizeLimit: 1Gi
      {{- end }}
      {{- if .Values.esmaster.backup.enabled }}
      - name: esbackup
        persistentVolumeClaim:
          claimName: {{ .Values.backupVolumeName }}
      {{- end }}
      {{- if .Values.esmaster.password }}
      - name: elasticconfig
        persistentVolumeClaim:
          claimName: elasticconfig
      - name: elasticsearch-config
        configMap:
          name: {{ .Release.Name }}-elasticsearch-config
      {{- end }}
  {{- if .Values.esworker.persistence.enabled }}
  volumeClaimTemplates:
  - metadata:
      name: esworkdata
    spec:
      storageClassName: {{ .Values.esworker.persistence.storageClassName }}
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: {{ .Values.esworker.persistence.size }}
  {{- end }}
