{{- if and .Values.nginx.enabled .Values.nginx.useSimpleDeployment }}
# ==============================================================================
# NGINX-SIMPLE.YAML - OpenResty Reverse Proxy with API Rate Limiting
# ==============================================================================
#
# RATE LIMITING (separate buckets for API and Web):
#
# API (/api/):
# - API keys (Authorization: Bearer or X-API-Key) - each key has own bucket
# - Falls back to IP if no API key
# - Two modes (can be enabled together):
#   1. Request-based: rateLimiting.api.enabled (requests per second) - ALL /api/ endpoints
#   2. Token-based:   rateLimiting.api.tokenBased.enabled (estimated LLM tokens)
#      - Only on chat endpoints: /api/chat/send-message, /api/chat/send-chat-message
#      - Estimates tokens from request body size (~4 chars = 1 token)
#
# WEB (/):
# - IP-based only (for browser requests)
# - Configurable via: rateLimiting.web.enabled, .requestsPerSecond, .burstCapacity
#
# Internal IPs (10.x, 172.x, 192.168.x, 127.x) are NOT rate limited
#
# LOG FORMAT:
# [RATELIMIT:API:REQ] OK  API_KEY=on_9B3hX****0vll requests_remaining=19 client_ip=1.2.3.4
# [RATELIMIT:API:TOK] OK  API_KEY=on_9B3hX****0vll tokens_remaining=1850 estimated_input=150
# [RATELIMIT:API:TOK] EXCEEDED API_KEY=on_9B3hX****0vll tokens_remaining=50 estimated_input=500
# [RATELIMIT:WEB] OK  IP=82.76.35.69 requests_remaining=58 (separate bucket)
# [RATELIMIT:API:REQ] SKIP internal_ip=10.42.184.225
#
# ==============================================================================

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "onyx.fullname" . }}-nginx-simple-config
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "onyx.labels" . | nindent 4 }}
data:
  default.conf: |
    map $http_upgrade $connection_upgrade {
        default "";
        websocket "upgrade";
    }

    upstream web_server {
        server {{ include "onyx.fullname" . }}-webserver:3000;
    }

    upstream api_server {
        server {{ include "onyx.fullname" . }}-api-service:8080;
    }

    {{- if .Values.nginx.rateLimiting.enabled }}
    # ==========================================================================
    # RATE LIMITING - API: {{ .Values.nginx.rateLimiting.api.requestsPerSecond | default 10 }} req/s
    # ==========================================================================
    lua_shared_dict rate_limit_store {{ .Values.nginx.rateLimiting.sharedDictSize }};

    init_by_lua_block {
        -- API rate limiting (for /api/ - uses API keys or falls back to IP)
        API_RATE_LIMIT_RPS = {{ .Values.nginx.rateLimiting.api.requestsPerSecond | default 10 }}
        API_RATE_LIMIT_BURST = {{ .Values.nginx.rateLimiting.api.burstCapacity | default 20 }}
        API_RATE_LIMIT_ENABLED = {{ .Values.nginx.rateLimiting.api.enabled | default true }}

        -- Token-based rate limiting (estimated from request body size)
        -- ~4 characters = 1 token (approximation for most LLMs)
        -- Only applied to specific chat endpoints
        TOKEN_RATE_LIMIT_ENABLED = {{ .Values.nginx.rateLimiting.api.tokenBased.enabled | default false }}
        TOKEN_RATE_LIMIT_TPS = {{ .Values.nginx.rateLimiting.api.tokenBased.tokensPerSecond | default 100 }}
        TOKEN_RATE_LIMIT_BURST = {{ .Values.nginx.rateLimiting.api.tokenBased.burstCapacity | default 2000 }}
        TOKEN_CHARS_PER_TOKEN = {{ .Values.nginx.rateLimiting.api.tokenBased.charsPerToken | default 4 }}

        -- Paths where token-based limiting is applied (prefix match)
        TOKEN_RATE_LIMIT_PATHS = {
            {{- if .Values.nginx.rateLimiting.api.tokenBased.paths }}
            {{- range .Values.nginx.rateLimiting.api.tokenBased.paths }}
            "{{ . }}",
            {{- end }}
            {{- else }}
            "/api/chat/send-message",
            "/api/chat/send-chat-message",
            {{- end }}
        }

        -- Check if path should use token-based limiting
        function is_token_limited_path(uri)
            for _, path in ipairs(TOKEN_RATE_LIMIT_PATHS) do
                if uri == path or string.sub(uri, 1, #path) == path then
                    return true
                end
            end
            return false
        end

        -- Web rate limiting (for / - IP-based only)
        WEB_RATE_LIMIT_RPS = {{ .Values.nginx.rateLimiting.web.requestsPerSecond | default 30 }}
        WEB_RATE_LIMIT_BURST = {{ .Values.nginx.rateLimiting.web.burstCapacity | default 60 }}
        WEB_RATE_LIMIT_ENABLED = {{ .Values.nginx.rateLimiting.web.enabled | default false }}

        RATE_LIMIT_LOGGING = {{ .Values.nginx.rateLimiting.enableLogging | default false }}

        -- Estimate tokens from body size (~4 chars = 1 token)
        function estimate_tokens(body_size)
            if not body_size or body_size <= 0 then return 1 end
            return math.ceil(body_size / TOKEN_CHARS_PER_TOKEN)
        end

        -- Internal IPs (RFC 1918) - NOT rate limited
        INTERNAL_IP_PATTERNS = {
            "^10%.",
            "^172%.1[6-9]%.",
            "^172%.2[0-9]%.",
            "^172%.3[0-1]%.",
            "^192%.168%.",
            "^127%.",
        }

        -- Whitelisted API keys (exempt from API rate limiting)
        WHITELISTED_KEYS = {
            {{- range .Values.nginx.rateLimiting.api.whitelistedKeys }}
            ["{{ . }}"] = true,
            {{- end }}
        }

        -- Whitelisted IPs (exempt from ALL rate limiting)
        WHITELISTED_IPS = {
            {{- range .Values.nginx.rateLimiting.whitelistedIPs }}
            ["{{ . }}"] = true,
            {{- end }}
        }

        function is_whitelisted_ip(ip)
            return ip and WHITELISTED_IPS[ip]
        end

        function is_internal_ip(ip)
            if not ip then return false end
            for _, pattern in ipairs(INTERNAL_IP_PATTERNS) do
                if string.match(ip, pattern) then return true end
            end
            return false
        end

        -- Mask API key: on_9B3hXYZ1234567890vll -> on_9B3hX****0vll
        function mask_api_key(key)
            if not key or #key < 16 then
                return key and string.rep("*", #key) or "unknown"
            end
            return string.sub(key, 1, 8) .. "****" .. string.sub(key, -4)
        end
    }
    {{- end }}

    server {
        listen 80;
        server_name _;

        proxy_connect_timeout {{ .Values.nginx.timeouts.connect }}s;
        proxy_send_timeout {{ .Values.nginx.timeouts.send }}s;
        proxy_read_timeout {{ .Values.nginx.timeouts.read }}s;
        client_max_body_size 100M;

        access_log /dev/stdout;
        {{- if and .Values.nginx.rateLimiting.enabled .Values.nginx.rateLimiting.enableLogging }}
        error_log /dev/stderr notice;
        {{- else }}
        error_log /dev/stderr;
        {{- end }}

        {{- if .Values.nginx.rateLimiting.enabled }}
        # API with rate limiting (separate buckets for API keys vs IPs)
        # Supports both request-based and token-based (estimated) limiting
        location /api/ {
            access_by_lua_block {
                -- Skip if both rate limiting types disabled
                if not API_RATE_LIMIT_ENABLED and not TOKEN_RATE_LIMIT_ENABLED then return end

                local store = ngx.shared.rate_limit_store

                local function get_client_ip()
                    local xff = ngx.var.http_x_forwarded_for
                    if xff then return string.match(xff, "^([^,]+)") end
                    return ngx.var.remote_addr
                end

                local function get_rate_key()
                    -- Priority 1: Bearer token
                    local auth = ngx.var.http_authorization
                    if auth then
                        local token = string.match(auth, "^[Bb]earer%s+(.+)$")
                        if token and token ~= "" then
                            return "api:key:" .. token, "API_KEY", token
                        end
                    end
                    -- Priority 2: X-API-Key header
                    local key = ngx.var.http_x_api_key
                    if key and key ~= "" then
                        return "api:key:" .. key, "API_KEY", key
                    end
                    -- Fallback: IP (prefixed with api: to separate from web)
                    local ip = get_client_ip()
                    return "api:ip:" .. (ip or "unknown"), "IP", nil
                end

                local client_ip = get_client_ip()

                -- Skip whitelisted IPs (exempt from ALL rate limiting)
                if is_whitelisted_ip(client_ip) then
                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:API] SKIP whitelisted_ip=", client_ip)
                    end
                    return
                end

                local rate_key, key_type, raw_key = get_rate_key()

                -- Skip internal IPs (only for IP-based limiting)
                if key_type == "IP" and is_internal_ip(client_ip) then
                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:API] SKIP internal_ip=", client_ip)
                    end
                    return
                end

                -- Check whitelist
                if key_type == "API_KEY" and raw_key and WHITELISTED_KEYS[raw_key] then
                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:API] SKIP whitelisted key=", mask_api_key(raw_key))
                    end
                    return
                end

                local display = key_type == "API_KEY" and mask_api_key(raw_key) or client_ip
                local now = ngx.now()

                -- ========== REQUEST-BASED RATE LIMITING ==========
                if API_RATE_LIMIT_ENABLED then
                    local tk = rate_key .. ":req:t"
                    local lk = rate_key .. ":req:l"

                    local tokens = store:get(tk)
                    local last = store:get(lk)

                    if not tokens then
                        tokens = API_RATE_LIMIT_BURST
                        last = now
                        if RATE_LIMIT_LOGGING then
                            ngx.log(ngx.NOTICE, "[RATELIMIT:API:REQ] NEW ", key_type, "=", display, " requests_remaining=", tokens, " client_ip=", client_ip)
                        end
                    else
                        tokens = math.min(API_RATE_LIMIT_BURST, tokens + (now - last) * API_RATE_LIMIT_RPS)
                    end

                    if tokens < 1 then
                        ngx.log(ngx.WARN, "[RATELIMIT:API:REQ] EXCEEDED ", key_type, "=", display, " client_ip=", client_ip)
                        ngx.status = {{ .Values.nginx.rateLimiting.limitExceededStatus | default 429 }}
                        ngx.header["Content-Type"] = "application/json"
                        ngx.header["Retry-After"] = tostring(math.ceil(1 / API_RATE_LIMIT_RPS))
                        ngx.say('{"error": "{{ .Values.nginx.rateLimiting.limitExceededMessage | default "Rate limit exceeded" }}"}')
                        return ngx.exit({{ .Values.nginx.rateLimiting.limitExceededStatus | default 429 }})
                    end

                    tokens = tokens - 1
                    store:set(tk, tokens, 60)
                    store:set(lk, now, 60)

                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:API:REQ] OK ", key_type, "=", display, " requests_remaining=", string.format("%.0f", tokens), " client_ip=", client_ip)
                    end
                end

                -- ========== TOKEN-BASED RATE LIMITING (chat endpoints only) ==========
                if TOKEN_RATE_LIMIT_ENABLED and is_token_limited_path(ngx.var.uri) then
                    -- Get request body size from Content-Length header
                    -- For chunked/streaming requests without Content-Length, use minimum estimate
                    local body_size = tonumber(ngx.var.content_length)
                    local estimated_tokens
                    if body_size and body_size > 0 then
                        estimated_tokens = estimate_tokens(body_size)
                    else
                        -- Chunked request or no body - use minimum token cost
                        estimated_tokens = 10  -- minimum cost for requests without Content-Length
                    end

                    local tk = rate_key .. ":tok:t"
                    local lk = rate_key .. ":tok:l"

                    local tokens = store:get(tk)
                    local last = store:get(lk)

                    if not tokens then
                        tokens = TOKEN_RATE_LIMIT_BURST
                        last = now
                        if RATE_LIMIT_LOGGING then
                            ngx.log(ngx.NOTICE, "[RATELIMIT:API:TOK] NEW ", key_type, "=", display, " tokens_remaining=", tokens, " estimated_input=", estimated_tokens, " client_ip=", client_ip)
                        end
                    else
                        tokens = math.min(TOKEN_RATE_LIMIT_BURST, tokens + (now - last) * TOKEN_RATE_LIMIT_TPS)
                    end

                    if tokens < estimated_tokens then
                        ngx.log(ngx.WARN, "[RATELIMIT:API:TOK] EXCEEDED ", key_type, "=", display, " tokens_remaining=", string.format("%.0f", tokens), " estimated_input=", estimated_tokens, " client_ip=", client_ip)
                        ngx.status = {{ .Values.nginx.rateLimiting.limitExceededStatus | default 429 }}
                        ngx.header["Content-Type"] = "application/json"
                        ngx.header["Retry-After"] = tostring(math.ceil(estimated_tokens / TOKEN_RATE_LIMIT_TPS))
                        ngx.say('{"error": "Token rate limit exceeded. Estimated tokens: ' .. estimated_tokens .. '"}')
                        return ngx.exit({{ .Values.nginx.rateLimiting.limitExceededStatus | default 429 }})
                    end

                    tokens = tokens - estimated_tokens
                    store:set(tk, tokens, 60)
                    store:set(lk, now, 60)

                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:API:TOK] OK ", key_type, "=", display, " tokens_remaining=", string.format("%.0f", tokens), " estimated_input=", estimated_tokens, " client_ip=", client_ip)
                    end
                end
            }

            proxy_pass http://api_server/;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Web frontend with optional IP-based rate limiting
        location / {
            access_by_lua_block {
                -- Skip if web rate limiting disabled
                if not WEB_RATE_LIMIT_ENABLED then return end

                local store = ngx.shared.rate_limit_store

                local function get_client_ip()
                    local xff = ngx.var.http_x_forwarded_for
                    if xff then return string.match(xff, "^([^,]+)") end
                    return ngx.var.remote_addr
                end

                local client_ip = get_client_ip()

                -- Skip whitelisted IPs (exempt from ALL rate limiting)
                if is_whitelisted_ip(client_ip) then
                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:WEB] SKIP whitelisted_ip=", client_ip)
                    end
                    return
                end

                -- Skip internal IPs
                if is_internal_ip(client_ip) then
                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:WEB] SKIP internal_ip=", client_ip)
                    end
                    return
                end

                local rate_key = "web:ip:" .. (client_ip or "unknown")
                local now = ngx.now()
                local tk = rate_key .. ":t"
                local lk = rate_key .. ":l"

                local tokens = store:get(tk)
                local last = store:get(lk)

                if not tokens then
                    tokens = WEB_RATE_LIMIT_BURST
                    last = now
                    if RATE_LIMIT_LOGGING then
                        ngx.log(ngx.NOTICE, "[RATELIMIT:WEB] NEW IP=", client_ip, " requests_remaining=", tokens)
                    end
                else
                    tokens = math.min(WEB_RATE_LIMIT_BURST, tokens + (now - last) * WEB_RATE_LIMIT_RPS)
                end

                if tokens < 1 then
                    ngx.log(ngx.WARN, "[RATELIMIT:WEB] EXCEEDED IP=", client_ip)
                    ngx.status = {{ .Values.nginx.rateLimiting.limitExceededStatus | default 429 }}
                    ngx.header["Content-Type"] = "text/html"
                    ngx.header["Retry-After"] = tostring(math.ceil(1 / WEB_RATE_LIMIT_RPS))
                    ngx.say("<html><body><h1>429 Too Many Requests</h1><p>Please slow down.</p></body></html>")
                    return ngx.exit({{ .Values.nginx.rateLimiting.limitExceededStatus | default 429 }})
                end

                tokens = tokens - 1
                store:set(tk, tokens, 60)
                store:set(lk, now, 60)

                if RATE_LIMIT_LOGGING then
                    ngx.log(ngx.NOTICE, "[RATELIMIT:WEB] OK IP=", client_ip, " requests_remaining=", string.format("%.0f", tokens))
                end
            }

            proxy_pass http://web_server;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
        }
        {{- else }}
        location /api/ {
            proxy_pass http://api_server/;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        location / {
            proxy_pass http://web_server;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection $connection_upgrade;
        }
        {{- end }}

        location /health {
            access_log off;
            return 200 "OK\n";
            add_header Content-Type text/plain;
        }
    }

---
apiVersion: v1
kind: Service
metadata:
  name: {{ include "onyx.fullname" . }}-nginx
  namespace: {{ .Release.Namespace }}
  labels:
    app: nginx
    {{- include "onyx.labels" . | nindent 4 }}
spec:
  type: {{ .Values.nginx.simple.serviceType | default "ClusterIP" }}
  ports:
  - port: 80
    targetPort: 80
    name: http
    {{- if and (eq (.Values.nginx.simple.serviceType | default "ClusterIP") "NodePort") .Values.nginx.simple.nodePort }}
    nodePort: {{ .Values.nginx.simple.nodePort }}
    {{- end }}
  selector:
    app: nginx

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "onyx.fullname" . }}-nginx
  namespace: {{ .Release.Namespace }}
  labels:
    app: nginx
    {{- include "onyx.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.nginx.simple.replicas | default 1 }}
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
      annotations:
        checksum/nginx-config: {{ .Values.nginx | toJson | sha256sum }}
    spec:
      containers:
      - name: openresty
        image: {{ .Values.nginx.simple.image | default "openresty/openresty" }}:{{ .Values.nginx.simple.tag | default "1.27.1.2-5-alpine-fat" }}
        imagePullPolicy: {{ .Values.global.pullPolicy }}
        ports:
        - containerPort: 80
          name: http
        volumeMounts:
        - name: nginx-config
          mountPath: /etc/nginx/conf.d/default.conf
          subPath: default.conf
        - name: nginx-cache
          mountPath: /var/cache/nginx
        - name: nginx-run
          mountPath: /var/run
        - name: openresty-run
          mountPath: /var/run/openresty
        - name: openresty-logs
          mountPath: /usr/local/openresty/nginx/logs
        resources:
          {{- toYaml .Values.nginx.simple.resources | nindent 10 }}
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
        {{- if .Values.nginx.simple.securityContext }}
        securityContext:
          {{- toYaml .Values.nginx.simple.securityContext | nindent 10 }}
        {{- end }}
      {{- if .Values.nginx.simple.podSecurityContext }}
      securityContext:
        {{- toYaml .Values.nginx.simple.podSecurityContext | nindent 8 }}
      {{- end }}
      volumes:
      - name: nginx-config
        configMap:
          name: {{ include "onyx.fullname" . }}-nginx-simple-config
      - name: nginx-cache
        emptyDir: {}
      - name: nginx-run
        emptyDir: {}
      - name: openresty-run
        emptyDir: {}
      - name: openresty-logs
        emptyDir: {}
{{- end }}
